# Кластеризация смешанных данных при наличии целевого признака

В промышленных задачах зачастую возникает проблема обработки разнородных данных разной природы, поступающих из разных источников. Применение классических supervised ML решений в этом случае не всегда целесообразно, поскольку тестовые выборки могут сильно отличаться от обучающих. Цель проекта - исследование алгоритмов unsupervised кластеризации данных промышленного домена.

Из множества подходов к кластеризации смешанных данных (от 1к до 100-200к) был выбран стабильный подход, состоящий из трех частей.
1. Расчет Gower distances (Gower, J. C. "A General Coefficient of Similarity and Some of Its Properties." Biometrics, vol. 27, no. 4, 1971, pp. 857–71. JSTOR, https://doi.org/10.2307/2528823. Accessed 10 Oct. 2025.). Кроме того, так как в данной задаче всегда присутствует целевой признак, была добавлена возможность рассчета весов входных признаков на основе взаимной информации с целевым признаком и возможность нормировки числовых признаков через IQR. Эти идеи были вдохновлены исследованием (Liu, P., Yuan, H., Ning, Y. et al. A modified and weighted Gower distance-based clustering analysis for mixed type data: a simulation and empirical analyses. BMC Med Res Methodol 24, 305 (2024). https://doi.org/10.1186/s12874-024-02427-8)

   Так как сложность O(N^2) по времени и по памяти расчет матрицы проводится на подвыборке до 8000 объектов. При желании и наличии ресурсов можно увеличить размер сэмпла до 10-20к, тем самым повысить точность алгоритма для больших выборок (100-200к). Мы же исходили из предположения закона о больших числах и том факте, что в задаче чаще будут выборки от 2-3 до 10-20 тысяч объектов. Тем самым случайная подвыборка в 8000 объектов достаточна для задачи и позволяет использовать подход при любых вычислительных ресурсах

2. Кластеризация на прерасчитанной метрике и расстояниях с помощью HBSCAN или Hierarchical agglomerative clustering (HAC). Для HDBSCAN производится перебор параметров и выбор лучших по Validity Index (так как Silhouette Score не сработает с выбросами, которые HDBSCAN определит в "кластер" -1). Для HAC подбор отсечения максимального количества кластеров проводится через Silhouette Score.

3. Если размер входной выборки больше 8000, то дальнейшая разметка проводилась с использованием FAISS HNSW и присвоение оставшимся объектам похожих кластеров, с чем FAISS замечательно справляется. (Matthijs Douze and Alexandr Guzhva and Chengqi Deng and Jeff Johnson and Gergely Szilvasy and Pierre-Emmanuel Mazaré and Maria Lomeli and Lucas Hosseini and Hervé Jégou "The Faiss library", arXiv, 2025, https://arxiv.org/abs/2401.08281)


Для анализа результатов строятся объясняющие деревья построения кластеров и внутрикластерные объясняющие деревья для исследования влияния объектов и их признаков, сформировавших кластер.

Streamlit link: https://mixed-data-clustering.streamlit.app/
